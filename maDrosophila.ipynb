{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maDrosophila.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardo0621/Drosophila/blob/master/maDrosophila.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK255E7YoEIt"
      },
      "source": [
        "# DeepLabCut 2.2 Toolbox - COLAB\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590444465547-SHXODUII311HEE407IL6/ke17ZwdGBToddI8pDm48kE4VnnB9_j2k1VP236ADqAFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQg9Vf0owGyf3dhfDKy8SxMujaKmp2B54Sb3VS1rO76Whq-cUhHVuKFlGUXsU9tJk/ezgif.com-video-to-gif.gif?format=1500w)\n",
        "\n",
        "https://github.com/DeepLabCut/DeepLabCut\n",
        "\n",
        "This notebook illustrates how to, for multi-animal projects, use the cloud-based GPU to:\n",
        "- create a multi-animal training set\n",
        "- train a network\n",
        "- evaluate a network\n",
        "- cross evaluate inference parameters\n",
        "- analyze novel videos\n",
        "- assemble tracklets\n",
        "- create quality check plots\n",
        "\n",
        "###This notebook assumes you already have a project folder with labeled data! \n",
        "\n",
        "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
        "\n",
        "This shows the most simple code to do so, but many of the functions have additional features, so please check out the docs on GitHub.\n",
        "\n",
        "Mathis et al, in prep. <- please note, we are providing this toolbox as an early access release; more feeatures and details will be released with the forthcoming paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txoddlM8hLKm"
      },
      "source": [
        "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q23BzhA6CXxu",
        "outputId": "9af5899a-54b2-4e21-d4ca-ffcf13bbadb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#(this will take a few minutes to install all the dependences!)\n",
        "!pip install git+https://github.com/DeepLabCut/DeepLabCut.git\n",
        "%reload_ext numpy\n",
        "%reload_ext scipy\n",
        "%reload_ext matplotlib\n",
        "%reload_ext mpl_toolkits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/DeepLabCut/DeepLabCut.git\n",
            "  Cloning https://github.com/DeepLabCut/DeepLabCut.git to /tmp/pip-req-build-alh5137b\n",
            "  Running command git clone -q https://github.com/DeepLabCut/DeepLabCut.git /tmp/pip-req-build-alh5137b\n",
            "Requirement already satisfied (use --upgrade to upgrade): deeplabcut==2.2b8 from git+https://github.com/DeepLabCut/DeepLabCut.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (2020.6.20)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.29.21)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.9)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.4.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (2.10.0)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (2020.0.133)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.2.9)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.2.0)\n",
            "Requirement already satisfied: numba==0.51.1 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.51.1)\n",
            "Requirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (3.1.3)\n",
            "Requirement already satisfied: moviepy<=1.0.1 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.2.3.5)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.16.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (4.4.0.44)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.1.2)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (2.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (2.23.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.16.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (50.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (1.15.0)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.12.0)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (3.4.4)\n",
            "Requirement already satisfied: tensorpack==0.9.8 in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.9.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (4.41.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from deeplabcut==2.2b8) (0.35.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->deeplabcut==2.2b8) (1.7.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug->deeplabcut==2.2b8) (2.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug->deeplabcut==2.2b8) (7.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug->deeplabcut==2.2b8) (4.1.2.30)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->deeplabcut==2.2b8) (4.8.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.51.1->deeplabcut==2.2b8) (0.34.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.3->deeplabcut==2.2b8) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.3->deeplabcut==2.2b8) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.3->deeplabcut==2.2b8) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->deeplabcut==2.2b8) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deeplabcut==2.2b8) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deeplabcut==2.2b8) (2.10)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from ruamel.yaml>=0.15.0->deeplabcut==2.2b8) (0.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deeplabcut==2.2b8) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deeplabcut==2.2b8) (2.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->deeplabcut==2.2b8) (0.16.0)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->deeplabcut==2.2b8) (2.7.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8->deeplabcut==2.2b8) (0.8.7)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8->deeplabcut==2.2b8) (1.0.0)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8->deeplabcut==2.2b8) (19.0.2)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8->deeplabcut==2.2b8) (5.4.8)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.4.2 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8->deeplabcut==2.2b8) (0.4.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorpack==0.9.8->deeplabcut==2.2b8) (1.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->deeplabcut==2.2b8) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->deeplabcut==2.2b8) (0.6.0)\n",
            "Building wheels for collected packages: deeplabcut\n",
            "  Building wheel for deeplabcut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeplabcut: filename=deeplabcut-2.2b8-cp36-none-any.whl size=668047 sha256=7a14524912023fca97386a06e1c7ceebc247efe3cabc068861b7edb0aa3298c4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yf0cre4o/wheels/57/9f/a0/9ed45695cd4d222c82264d0c3cc2d0bcb0dec399fbfbd49264\n",
            "Successfully built deeplabcut\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y36K4Eux3h-X",
        "outputId": "10de72c1-ec6e-4db7-b021-376b34bb4bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Use TensorFlow 1.x:\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTwAcbq2-FZz",
        "outputId": "6b600572-efa4-429f-eae9-c6708b08ccb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#GUIs don't work on the cloud, so we supress them:\n",
        "import os\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "import deeplabcut\n",
        "\n",
        "# Suppress tensorflow warning messages:\n",
        "import tensorflow as tf\n",
        "\n",
        "vers = (tf.__version__).split(\".\")\n",
        "if int(vers[0]) == 1 and int(vers[1]) > 12:\n",
        "    TF = tf.compat.v1  # behaves differently before 1.13\n",
        "else:\n",
        "    TF = tf\n",
        "\n",
        "TF.logging.set_verbosity(TF.logging.ERROR)\n",
        "DEBUG = True and \"DEBUG\" in os.environ and os.environ[\"DEBUG\"]\n",
        "from deeplabcut import DEBUG"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-nlTkri4HZ"
      },
      "source": [
        "## Link your Google Drive (with your labeled data):\n",
        "\n",
        "### First, place your porject folder into you google drive! \"i.e. move the folder named \"Project-YourName-TheDate\" into google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS4Q4UkR9rgG",
        "outputId": "0cfd9c31-8df9-43a7-ddab-38c18c438640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Now, let's link to your GoogleDrive. Run this cell and follow the authorization instructions:\n",
        "#(We recommend putting a copy of the github repo in your google drive if you are using the demo \"examples\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frnj1RVDyEqs"
      },
      "source": [
        "## YOU WILL NEED TO EDIT THE PROJECT PATH **in the config.yaml file** TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
        "\n",
        "Typically, this will be: /content/drive/My Drive/yourProjectFolderName\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhENAlQnFENJ",
        "outputId": "e3d3f812-6e90-4284-f71e-18dc00c7fa79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# PLEASE EDIT THIS:\n",
        "  \n",
        "ProjectFolderName = 'maDrosophila'\n",
        "VideoType = 'mov' #, mp4, MOV, or avi, whatever you uploaded!\n",
        "\n",
        "\n",
        "# we are going to assume you put videos you want to analyze in the \"videos\" folder, but if this is NOT true, edit below:\n",
        "videofile_path = ['/content/drive/My Drive/'+ProjectFolderName+'/videos/'] #Enter the list of videos or folder to analyze.\n",
        "videofile_path\n",
        "\n",
        "#This creates a path variable that links to your google drive copy\n",
        "#No need to edit this, as you set it when you passed the ProjectFolderName (above): \n",
        "path_config_file = '/content/drive/My Drive/'+ProjectFolderName+'/config.yaml'\n",
        "path_config_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/maDrosophila/config.yaml'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNi9s1dboEJN"
      },
      "source": [
        "## Create a multi-animal training dataset:\n",
        "### You must do this step inside of Colab:\n",
        "\n",
        "- Reminder: you must connect EVERY bodypart in a skeleton before you run this step! See docs for crucial details on how to do this effciently: https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/functionDetails.md#b-configure-the-project-\n",
        "\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589256735280-SCN7CROSJNJWCDS6EK5T/ke17ZwdGBToddI8pDm48kB08p9-rNkpPD7A3fw8YFjZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIno0kSvzOWihTW1zp8-1-7mzYxUQjsVr2n3nmNdVcso4/bodyparts-skeleton.png?format=1000w)\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589410182515-9SJO9MML6CNCXBAWQ6Z6/ke17ZwdGBToddI8pDm48kJ1oJoOIxBAgRD2ClXVCmKFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxBw7VlGKDQO2xTcc51Yv6DahHgScLwHgvMZoEtbzk_9vMJY_JknNFgVzVQ2g0FD_s/ezgif.com-video-to-gif+%2811%29.gif?format=750w)\n",
        "\n",
        "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
        "\n",
        "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
        "\n",
        "Now it is the time to start training the network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eMeUwgxPoEJP",
        "outputId": "415abdda-c5ff-4061-ce83-fb0075132f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "deeplabcut.cropimagesandlabels(path_config_file, size=(400, 400), userfeedback=False)\n",
        "\n",
        "#if you labeled on Windows, please set the windows2linux=True:\n",
        "deeplabcut.create_multianimaltraining_dataset(path_config_file, windows2linux=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/maDrosophila/training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1  already exists!\n",
            "Utilizing the following graph: [[1, 2], [0, 1], [1, 3], [1, 4], [2, 3], [0, 4], [0, 3], [3, 4], [0, 2]]\n",
            "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/330 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating training data for  1 0.95\n",
            "This can take some time...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 330/330 [01:50<00:00,  2.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4FczXGDoEJU"
      },
      "source": [
        "## Start training:\n",
        "This function trains the network for a specific shuffle of the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pOvDq_2oEJW",
        "outputId": "ecb38e24-98f3-464e-c7e7-b7e9b93391cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
        "#if that happens, you can reload from a saved point. \n",
        "#Typically, you want to train to 50,000 iterations.\n",
        "#more info and there are more things you can set: https://github.com/AlexEMG/DeepLabCut/blob/master/docs/functionDetails.md#g-train-the-network\n",
        "\n",
        "#which shuffle do you want to train?\n",
        "shuffle = 1\n",
        "deeplabcut.train_network(path_config_file, shuffle=shuffle, displayiters=100,saveiters=1000)\n",
        "\n",
        "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 50K iterations). \n",
        "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry...."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 8,\n",
            " 'crop_pad': 0,\n",
            " 'cropratio': 0.4,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'display_iters': 500,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 0.05,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'max_input_size': 1500,\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/Documentation_data-maDrosophila_95shuffle1.pickle',\n",
            " 'min_input_size': 64,\n",
            " 'mirror': False,\n",
            " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
            " 'net_type': 'resnet_50',\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'adam',\n",
            " 'pafwidth': 20,\n",
            " 'pairwise_huber_loss': False,\n",
            " 'pairwise_loss_weight': 0.1,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'pos_dist_thresh': 17,\n",
            " 'project_path': '/content/drive/My Drive/maDrosophila',\n",
            " 'regularize': False,\n",
            " 'rotation': 25,\n",
            " 'rotratio': 0.4,\n",
            " 'save_iters': 10000,\n",
            " 'scale_jitter_lo': 0.5,\n",
            " 'scale_jitter_up': 1.25,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/train/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selecting multi-animal trainer\n",
            "Activating limb prediction...\n",
            "Starting with multi-animal imaug + adam pose-dataset loader.\n",
            "Batch Size is 8\n",
            "Getting specs multi-animal-imgaug 9 5\n",
            "Initializing ResNet\n",
            "Loading ImageNet-pretrained resnet_50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0m__swig_getmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m     \u001b[0m__getattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_getattr\u001b[0;34m(self, class_type, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_swig_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swig_getattr_nondynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_getattr_nondynamic\u001b[0;34m(self, class_type, name, static)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mstatic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'object' has no attribute '__getattr__'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-65c607623552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#which shuffle do you want to train?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 50K iterations).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[1;32m    178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/train_multianimal.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_preloading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menqueue_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtrain_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/train_multianimal.py\u001b[0m in \u001b[0;36mget_optimizer\u001b[0;34m(loss_op, cfg)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown optimizer {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_train_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/slim/python/slim/learning.py\u001b[0m in \u001b[0;36mcreate_train_op\u001b[0;34m(total_loss, optimizer, global_step, update_ops, variables_to_train, clip_gradient_norm, summarize_gradients, gate_gradients, aggregation_method, colocate_gradients_with_ops, gradient_multipliers, check_numerics)\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       check_numerics=check_numerics)\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/training/python/training/training.py\u001b[0m in \u001b[0;36mcreate_train_op\u001b[0;34m(total_loss, optimizer, global_step, update_ops, variables_to_train, transform_grads_fn, summarize_gradients, gate_gradients, aggregation_method, colocate_gradients_with_ops, check_numerics)\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m       \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m       colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtransform_grads_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    159\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 t_in.dtype != dtypes.resource):\n\u001b[1;32m    706\u001b[0m               \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0min_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m               \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    638\u001b[0m       c_api.TF_GraphSetTensorShape_wrapper(\n\u001b[1;32m    639\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m           \u001b[0mdim_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m           unknown_shape)\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_tf_output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;31m# cache of executor(s) stored for every session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/c_api_util.py\u001b[0m in \u001b[0;36mtf_output\u001b[0;34m(c_op, index)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mWrapped\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \"\"\"\n\u001b[0;32m--> 186\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1463\u001b[0m     \u001b[0m__swig_destroy__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_TF_Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[0m__del__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m     \u001b[0m__swig_setmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m     \u001b[0m__setattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m     \u001b[0m__swig_getmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0m__getattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_setattr\u001b[0;34m(self, class_type, name, value)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swig_setattr_nondynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m_swig_setattr_nondynamic\u001b[0;34m(self, class_type, name, value, static)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"this\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SwigPyObject'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__swig_setmethods__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiDwIVf5-3H_"
      },
      "source": [
        "**When you hit \"STOP\" you will get a KeyInterrupt \"error\"! No worries! :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZygsb2DoEJc"
      },
      "source": [
        "## Start evaluating: for maDLC, this is several steps. \n",
        " - First, we evaluate the pose estimation performance, and then we can cross-valudate optimal inference parameters.\n",
        "\n",
        "- This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images) and stores the results as .5 and .csv file in a subdirectory under **evaluation-results**\n",
        "\n",
        "- If the scoremaps do not look accurate, don't proceed to tracklet assembly; please consider (1) adding more data, (2) adding more bodyparts!\n",
        "\n",
        "Here is an example of what you'd aim to see before proceeding:\n",
        "\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590535809087-X655WY9W1MW1MY1I7DHE/ke17ZwdGBToddI8pDm48kBoswZhKnUtAF7-bTXgw67EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc5tTP1cnANTUwNNPnYFjIp6XbP9N1GxIgAkxvBVqt0UvLpPHYwvNQTwHg8f_Zu8ZF/evaluation.png?format=1000w)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv4zlbrnoEJg",
        "outputId": "ad426ad1-d7cd-4f4b-fd7e-bfcde3e5f518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#%matplotlib notebook\n",
        "#let's evaluate first:\n",
        "deeplabcut.evaluate_network(path_config_file,Shuffles=[shuffle], plotting=True,c_engine=False)\n",
        "#plot a few scoremaps:\n",
        "deeplabcut.extract_save_all_maps(path_config_file, shuffle=shuffle, Indices=[0])\n",
        "\n",
        "\n",
        "#and begin to cross-validate:\n",
        "deeplabcut.evaluate_multianimal_crossvalidate(\n",
        "            path_config_file,\n",
        "            Shuffles=[shuffle],\n",
        "            edgewisecondition=True,\n",
        "            leastbpts=1,\n",
        "            init_points=20,\n",
        "            n_iter=50,\n",
        "            target='rpck_train',\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running  DLC_resnet50_maDrosophilaoct1shuffle1_20000  with # of trainingiterations: 20000\n",
            "Initializing ResNet\n",
            "Activating extracting of PAFs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Analyzing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "1it [00:01,  1.21s/it]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "3it [00:01,  1.14it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "6it [00:01,  2.09it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "8it [00:01,  2.77it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "15it [00:02,  7.17it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "17it [00:02,  7.95it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "19it [00:02,  8.78it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "22it [00:03,  4.38it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "27it [00:06,  2.44it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "28it [00:06,  2.37it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "30it [00:07,  2.15it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "31it [00:07,  2.79it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "34it [00:07,  4.97it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "36it [00:08,  6.42it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "38it [00:08,  7.58it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "39it [00:08,  8.01it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "41it [00:08,  8.68it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "45it [00:09,  8.71it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "47it [00:09,  8.93it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "48it [00:09,  6.59it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "49it [00:09,  7.30it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "56it [00:12,  2.61it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "57it [00:12,  2.57it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "58it [00:13,  2.45it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "63it [00:14,  4.08it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "66it [00:15,  5.56it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "68it [00:15,  6.42it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "69it [00:15,  7.07it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "75it [00:16,  8.14it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "77it [00:16,  8.62it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "78it [00:16,  8.71it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "79it [00:16,  8.78it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "85it [00:17,  8.44it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "87it [00:17,  8.68it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "88it [00:17,  9.01it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "89it [00:17,  9.09it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "91it [00:18,  9.12it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "94it [00:18,  8.91it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "95it [00:18,  9.06it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "103it [00:19,  7.54it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "104it [00:19,  8.03it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "108it [00:20,  8.52it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "109it [00:20,  8.90it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "111it [00:20,  9.04it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "113it [00:20,  8.65it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "114it [00:20,  8.84it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "115it [00:20,  8.90it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "118it [00:21,  8.51it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "119it [00:21,  6.48it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "121it [00:21,  7.48it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "122it [00:21,  7.88it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "126it [00:22,  6.45it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "127it [00:22,  7.07it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "129it [00:22,  8.01it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "133it [00:23,  8.27it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "135it [00:23,  8.38it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "136it [00:23,  8.60it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "137it [00:23,  6.58it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "140it [00:24,  7.69it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "142it [00:24,  7.95it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "149it [00:25,  8.49it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "151it [00:25,  8.47it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "157it [00:26,  7.61it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "158it [00:26,  8.14it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "159it [00:26,  8.56it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "165it [00:27,  8.23it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "166it [00:27,  8.58it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "168it [00:27,  8.86it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "178it [00:28,  8.32it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "184it [00:29,  8.33it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "185it [00:29,  8.62it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "187it [00:30,  5.75it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "189it [00:30,  5.50it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "205it [00:32,  8.40it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "207it [00:32,  6.29it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "208it [00:33,  6.92it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "209it [00:33,  7.45it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "216it [00:33,  8.09it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "218it [00:34,  8.61it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "219it [00:34,  8.60it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "224it [00:35,  6.30it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "226it [00:35,  7.37it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "228it [00:35,  8.00it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "229it [00:35,  8.40it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "232it [00:35,  8.43it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "236it [00:36,  8.08it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "238it [00:36,  8.44it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "244it [00:37,  6.88it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "246it [00:37,  7.80it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "247it [00:37,  8.08it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "248it [00:38,  5.23it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "258it [00:39,  8.05it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "259it [00:39,  8.52it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "260it [00:39,  6.57it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "268it [00:40,  7.88it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "269it [00:40,  8.04it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "271it [00:41,  8.35it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "273it [00:41,  8.34it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "276it [00:41,  8.63it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "277it [00:41,  6.53it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "279it [00:42,  7.32it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "284it [00:42,  8.55it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "285it [00:42,  8.87it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "287it [00:43,  8.48it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "288it [00:43,  8.73it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "293it [00:43,  8.17it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "295it [00:44,  6.46it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "296it [00:44,  7.03it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "297it [00:44,  7.53it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "299it [00:44,  7.98it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "308it [00:45,  7.92it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "310it [00:46,  5.03it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "315it [00:46,  6.71it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "316it [00:46,  7.27it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "319it [00:47,  7.93it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "321it [00:47,  8.18it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "325it [00:47,  8.57it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "327it [00:48,  8.43it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "328it [00:48,  8.27it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "329it [00:48,  8.47it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "336it [00:49,  8.11it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "339it [00:49,  8.21it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "346it [00:50,  6.93it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "347it [00:50,  7.41it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "348it [00:50,  7.74it/s]/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/evaluate_multianimal.py:280: RuntimeWarning: All-NaN slice encountered\n",
            "  distnorm[imageindex] = np.nanmax(lengths)\n",
            "350it [00:51,  6.85it/s]\n",
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "##########################################&1\n",
            "Euclidean distance statistics per individual (in pixels)\n",
            "                  min       max      mean       std  percentile_25  percentile_50  percentile_75\n",
            "individuals                                                                                     \n",
            "dros1        1.622099  3.650940  2.600407  1.356562       2.110333       2.557373       3.052332\n",
            "dros2        1.597882  3.218988  2.382077  1.138432       1.996926       2.335404       2.741423\n",
            "##########################################\n",
            "Euclidean distance statistics per bodypart (in pixels)\n",
            "                min       max      mean       std  percentile_25  percentile_50  percentile_75\n",
            "bodyparts                                                                                     \n",
            "abdomen    2.029540  2.126824  2.078182  1.410206       2.053861       2.078182       2.102503\n",
            "head       2.734117  2.806353  2.770235  0.685920       2.752176       2.770235       2.788294\n",
            "leftwing   2.215619  2.572106  2.393862  0.868634       2.304741       2.393862       2.482984\n",
            "rightwing  2.735087  3.075374  2.905231  0.949109       2.820159       2.905231       2.990303\n",
            "torax      2.708345  2.905860  2.807103  0.936913       2.757724       2.807103       2.856481\n",
            "Done and results stored for snapshot:  snapshot-20000\n",
            "/content/drive/My Drive/maDrosophila/evaluation-results/  already exists!\n",
            "/content/drive/My Drive/maDrosophila/evaluation-results/iteration-0/maDrosophilaoct1-trainset95shuffle1  already exists!\n",
            "Initializing ResNet\n",
            "Activating extracting of PAFs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Analyzing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  2.60it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving plots...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n",
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/maDrosophila/evaluation-results/iteration-0/maDrosophilaoct1-trainset95shuffle1  already exists!\n",
            "/content/drive/My Drive/maDrosophila/evaluation-results/iteration-0/maDrosophilaoct1-trainset95shuffle1/DLC_resnet50_maDrosophilaoct1shuffle1_20000-snapshot-20000.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing distances...\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck 0.1513435713636014 rpck train: 0.7215027519285384\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck 0.030743161061692684 rpck train: 0.4200585974700132\n",
            "rmse 10.70729920176197 miss 1.5 hit 2.0\n",
            "rpck 0.1513435713636014 rpck train: 0.7199870532085919\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck 0.11706751040393416 rpck train: 0.650552987329071\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.08644067458816679 rpck train: 0.6165709599598467\n",
            "rmse 10.36195904740147 miss 0.375 hit 3.375\n",
            "rpck 0.1364180362127464 rpck train: 0.6678166592830114\n",
            "rmse 9.98753845468232 miss 0.0 hit 3.5555555555555554\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck 0.19441820480086214 rpck train: 0.6328860785984017\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.1513435713636014 rpck train: 0.7183589566187789\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck 0.12810099637185768 rpck train: 0.6055321154033705\n",
            "rmse 9.59183640107555 miss 0.45454545454545453 hit 2.6363636363636362\n",
            "rpck 0.14918432999000272 rpck train: 0.6882931347672371\n",
            "rmse 9.698164807853457 miss 0.21428571428571427 hit 2.7857142857142856\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck 0.11706751040393416 rpck train: 0.650552987329071\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.030743161061692684 rpck train: 0.4200585974700132\n",
            "rmse 10.70729920176197 miss 1.5 hit 2.0\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck nan rpck train: nan\n",
            "rmse nan miss nan hit nan\n",
            "rpck 0.1513435713636014 rpck train: 0.7176476434030433\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck 0.19441820480086214 rpck train: 0.6328860785984017\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.12810099637185768 rpck train: 0.5944423954278026\n",
            "rmse 9.59183640107555 miss 0.45454545454545453 hit 2.6363636363636362\n",
            "rpck 0.19441820480086214 rpck train: 0.6328860785984017\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.14918432999000272 rpck train: 0.7070213426225336\n",
            "rmse 9.698164807853457 miss 0.21428571428571427 hit 2.7857142857142856\n",
            "rpck 0.1364180362127464 rpck train: 0.6729915434983145\n",
            "rmse 9.98753845468232 miss 0.0 hit 3.5555555555555554\n",
            "rpck 0.2524750306560637 rpck train: 0.6343724979833222\n",
            "rmse 8.473630155087621 miss 0.0 hit 5.0\n",
            "rpck 0.14918432999000272 rpck train: 0.7102182304466976\n",
            "rmse 9.698164807853457 miss 0.21428571428571427 hit 2.7857142857142856\n",
            "rpck 0.11843744396559398 rpck train: 0.5411465465749636\n",
            "rmse 9.703958030440122 miss 0.5454545454545454 hit 2.5454545454545454\n",
            "rpck 0.07506327622044177 rpck train: 0.5024170225000341\n",
            "rmse 10.374181392289156 miss 0.8333333333333334 hit 2.1666666666666665\n",
            "rpck 0.19441820480086214 rpck train: 0.6299985269465158\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.19441820480086214 rpck train: 0.6301763735479428\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.11706751040393416 rpck train: 0.6586991859096324\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.19441820480086214 rpck train: 0.6305290694553551\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.19441820480086214 rpck train: 0.6319402300082734\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.11706751040393416 rpck train: 0.6631933525579664\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.19441820480086214 rpck train: 0.6305290694553551\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.19441820480086214 rpck train: 0.6299985269465158\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.19441820480086214 rpck train: 0.6301763735479428\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.030743161061692684 rpck train: 0.4330858290017146\n",
            "rmse 10.70729920176197 miss 1.5 hit 2.0\n",
            "rpck 0.1513435713636014 rpck train: 0.7199870532085919\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck 0.07506327622044177 rpck train: 0.5094731310297311\n",
            "rmse 10.374181392289156 miss 0.8333333333333334 hit 2.1666666666666665\n",
            "rpck 0.14918432999000272 rpck train: 0.7002270940150306\n",
            "rmse 9.698164807853457 miss 0.21428571428571427 hit 2.7857142857142856\n",
            "rpck 0.1513435713636014 rpck train: 0.7165315209638544\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck 0.1364180362127464 rpck train: 0.6678166592830114\n",
            "rmse 9.98753845468232 miss 0.0 hit 3.5555555555555554\n",
            "rpck 0.04413977705843703 rpck train: 0.4766115955697667\n",
            "rmse 10.3733085990084 miss 1.0 hit 2.2\n",
            "rpck 0.1513435713636014 rpck train: 0.7177805505092371\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck 0.1513435713636014 rpck train: 0.7200426991311761\n",
            "rmse 9.977305917991135 miss 0.0 hit 3.0\n",
            "rpck 0.04413977705843703 rpck train: 0.47132312815382305\n",
            "rmse 10.3733085990084 miss 1.0 hit 2.2\n",
            "rpck 0.14918432999000272 rpck train: 0.6950736518484009\n",
            "rmse 9.698164807853457 miss 0.21428571428571427 hit 2.7857142857142856\n",
            "rpck 0.19441820480086214 rpck train: 0.6319402300082734\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.12810099637185768 rpck train: 0.5565210193477265\n",
            "rmse 9.59183640107555 miss 0.45454545454545453 hit 2.6363636363636362\n",
            "rpck 0.11706751040393416 rpck train: 0.6534676999832547\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.11706751040393416 rpck train: 0.6534676999832547\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.08644067458816679 rpck train: 0.623585307497613\n",
            "rmse 10.36195904740147 miss 0.375 hit 3.375\n",
            "rpck 0.030743161061692684 rpck train: 0.4543488452963132\n",
            "rmse 10.70729920176197 miss 1.5 hit 2.0\n",
            "rpck 0.2524750306560637 rpck train: 0.6301213971838968\n",
            "rmse 8.473630155087621 miss 0.0 hit 5.0\n",
            "rpck 0.2524750306560637 rpck train: 0.6307643613341763\n",
            "rmse 8.473630155087621 miss 0.0 hit 5.0\n",
            "rpck 0.11911322394380765 rpck train: 0.6141416118618139\n",
            "rmse 9.738743078219477 miss 0.4166666666666667 hit 2.6666666666666665\n",
            "rpck 0.11706751040393416 rpck train: 0.6586991859096324\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.1328075709946127 rpck train: 0.6514134652519187\n",
            "rmse 9.765845027745176 miss 0.3076923076923077 hit 2.769230769230769\n",
            "rpck 0.19441820480086214 rpck train: 0.6328860785984017\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.12810099637185768 rpck train: 0.5686853871018507\n",
            "rmse 9.59183640107555 miss 0.45454545454545453 hit 2.6363636363636362\n",
            "rpck 0.042351234975592546 rpck train: 0.4651120560496423\n",
            "rmse 10.606674801597043 miss 1.2 hit 2.0\n",
            "rpck 0.19441820480086214 rpck train: 0.6299985269465158\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.19441820480086214 rpck train: 0.6299985269465158\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.19441820480086214 rpck train: 0.6299985269465158\n",
            "rmse 9.19390174801638 miss 0.0 hit 4.5\n",
            "rpck 0.11706751040393416 rpck train: 0.6534676999832547\n",
            "rmse 10.19044381427476 miss 0.2222222222222222 hit 3.3333333333333335\n",
            "rpck 0.030743161061692684 rpck train: 0.4197812069520348\n",
            "rmse 10.70729920176197 miss 1.5 hit 2.0\n",
            "rpck 0.2524750306560637 rpck train: 0.6299985269465158\n",
            "rmse 8.473630155087621 miss 0.0 hit 5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rpck 0.1364180362127464 rpck train: 0.6678166592830114\n",
            "rmse 9.98753845468232 miss 0.0 hit 3.5555555555555554\n",
            "/content/drive/My Drive/maDrosophila/evaluation-results/iteration-0/maDrosophilaoct1-trainset95shuffle1/DLC_resnet50_maDrosophilaoct1shuffle1_20000-snapshot-20000.h5\n",
            "Saving optimal inference parameters...\n",
            "   train_iter  train_frac  shuffle  rmse_train  hits_train  misses_train  falsepos_train  ndetects_train  pck_train  rpck_train  rmse_test  hits_test  misses_test  falsepos_test  ndetects_test  pck_test  rpck_test\n",
            "0     20000.0        95.0      1.0     2.41524    4.140097      0.091787        0.280193        1.294686   0.950941    0.865091   9.977306        3.0          0.0       0.214286            1.0  0.188095   0.313843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MbIL5z2U7fp"
      },
      "source": [
        "^ NOTE: this optimized part detection for video analysis. It cannot optimze for tracking, as this is use-case dependent. Please check the docs on how you can set the best parameters and modify/test before \"final\" tracking parameters. You can use COLAB to analyze videos, but afterwards we recommend using the outputs/proejct folder locally to run the final steps! They do not require a GPU. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFLSKKfoEJk"
      },
      "source": [
        "## Start Analyzing videos: \n",
        "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
        "\n",
        "The results are stored in hd5 file in the same directory where the video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LZiS_0oEJl",
        "outputId": "e5a5bd71-8a82-4115-95a6-2dbbe5d68867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Start Analyzing my video(s)!\")\n",
        "scorername = deeplabcut.analyze_videos(path_config_file, \n",
        "                                       videofile_path, \n",
        "                                       shuffle=shuffle, \n",
        "                                       videotype=VideoType, \n",
        "                                       c_engine=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3], [4]],\n",
            " 'all_joints_names': ['leftwing', 'rightwing', 'head', 'torax', 'abdomen'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_maDrosophilaoct1/maDrosophila_RicardoDiaz95shuffle1.pickle',\n",
            " 'dataset_type': 'multi-animal-imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'minconfidence': 0.01,\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'nmsradius': 5.0,\n",
            " 'num_joints': 5,\n",
            " 'num_limbs': 9,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_graph': [[1, 2],\n",
            "                             [0, 1],\n",
            "                             [1, 3],\n",
            "                             [1, 4],\n",
            "                             [2, 3],\n",
            "                             [0, 4],\n",
            "                             [0, 3],\n",
            "                             [3, 4],\n",
            "                             [0, 2]],\n",
            " 'partaffinityfield_predict': True,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Start Analyzing my video(s)!\n",
            "Using snapshot-20000 for model /content/drive/My Drive/maDrosophila/dlc-models/iteration-0/maDrosophilaoct1-trainset95shuffle1\n",
            "Initializing ResNet\n",
            "Activating extracting of PAFs\n",
            "Analyzing all the videos in the directory...\n",
            "Starting to analyze %  /content/drive/My Drive/maDrosophila/videos/Movie.S3.mov\n",
            "/content/drive/My Drive/maDrosophila/videos  already exists!\n",
            "Loading  /content/drive/My Drive/maDrosophila/videos/Movie.S3.mov\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/301 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Duration of video [s]:  10.04 , recorded with  29.97 fps!\n",
            "Overall # of frames:  301  found with (before cropping) frame dimensions:  1280 720\n",
            "Starting to extract posture\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "310it [00:30, 11.86it/s]                         "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Detected frames:  301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r310it [00:30, 10.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving results in /content/drive/My Drive/maDrosophila/videos...\n",
            "The videos are analyzed. Time to assemble animals and track 'em... \n",
            " Call 'create_video_with_all_detections' to check multi-animal detection quality before tracking.\n",
            "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRLS2_-r55K"
      },
      "source": [
        "## The steps below work on a single video at a time.\n",
        "- Here you can create a video to check the pose estimation detection quality! If this looks good, proceed to tracklet conversions with the interactive GUI (ouside of COLAB for now), or if you know your optimal parameters, you can automate this and run the additional steps shown in a few cells down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mWwX5bTc5C",
        "outputId": "01bf41f6-bad5-4959-b0aa-7d90dbab6176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# PROTIP: look at the output video; if the pose estimation (i.e. key points) don't look good, don't proceed with tracking - add more data to your training set and re-train!\n",
        "from deeplabcut.utils import auxiliaryfunctions\n",
        "#scorername, DLCscorerlegacy = auxiliaryfunctions.GetScorerName(path_config_file, shuffle, trainFraction=0)\n",
        "print(\"scorename is: \"+scorername)\n",
        "\n",
        "#inferencefg_path = '/content/drive/My Drive/mwm-penguins-2020-03-31/dlc-models/iteration-0/mwmMar31-trainset95shuffle1/test/inference_cfg.yaml'\n",
        "#scorername, DLCscorerlegacy = auxiliaryfunctions.GetScorerName(\n",
        " #   inferencefg_path, shuffle, trainFraction=0\n",
        "#)\n",
        "\n",
        "#let's check a specific video:\n",
        "Specific_videofile = '/content/drive/My Drive/maDrosophila/videos/Movie.S3.mov'\n",
        "\n",
        "deeplabcut.create_video_with_all_detections(path_config_file, [Specific_videofile], scorername)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 17/301 [00:00<00:01, 163.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "scorename is: DLC_resnet50_maDrosophilaoct1shuffle1_20000\n",
            "Creating labeled video for  Movie.S3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 301/301 [00:03<00:00, 83.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78x3BbotIsuO"
      },
      "source": [
        "## Convert Detections to Tracklets:\n",
        "\n",
        "- The idea is that you test and adapt hyperparameters for tracking outside of COLAB. Once you have good parameters, this can be automated on future videos. Shown here!\n",
        "\n",
        "- I.e., instead of always doing an interactive parameter setting step, you can simply convert tracklets to .h5 files using these parameters (see GitHub for more info)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIvXM7TXIs-U"
      },
      "source": [
        "#assemble tracklets:\n",
        "#read the docs: which tracker to test out (you can run this twice to try multiple):\n",
        "tracktype= 'box' #box, skeleton\n",
        "\n",
        "deeplabcut.convert_detections2tracklets(path_config_file, Specific_videofile, videotype=VideoType,\n",
        "                                                    shuffle=shuffle, track_method=tracktype, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHH9lCM7JCZ0"
      },
      "source": [
        "## Now you should manually verify the tracks and correct them if needed! [currently only working outside of COLAB]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocRzxq7fJCjm"
      },
      "source": [
        "''' here is the code you would need:\n",
        "os.environ[\"DLClight\"]=\"False\"\n",
        "import deeplabcut\n",
        "\n",
        "#ATTENTION:\n",
        "picklefile = '/...._10000_bx.pickle' #(see your video folder for path i.e. right click and say copy path!!!)\n",
        "vid ='/yourVIDEO.mp4'\n",
        "#if you want occlusions filled in, tell us how many frames to fill in, i.e. if there is a gap in data:\n",
        "framestofill = 10. #note, put \"0\" if you want ALL gaps filled!\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from deeplabcut.refine_training_dataset.tracklets import refine_tracklets\n",
        "TrackletManager, TrackletVisualizer = refine_tracklets(path_config_file, \n",
        "                                                          picklefile, \n",
        "                                                          Specific_videofile, \n",
        "                                                          min_swap_frac=0,\n",
        "                                                          min_tracklet_frac=0, \n",
        "                                                          max_gap=framestofill)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUOKrLJRseUX"
      },
      "source": [
        "## Let's assume you have great tracking parameters, and you want to analyze a full set of videos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6izVWX8sdzL"
      },
      "source": [
        "#^^^^^^^^^You do NOT neeed to run if you hit \"save\" in the GUI ^^^^^^^^^^\n",
        "#this is just if you want to run the same parameters over a set of videos!\n",
        "picklefile = '/content/drive/My Drive/mwm-penguins-2020-03-31/videos/penguindemoDLC_resnet50_mwmMar31shuffle1_22000_bx.pickle' #(see your video folder for path i.e. right click and say copy path!!!)\n",
        "vid ='/content/drive/My Drive/mwm-penguins-2020-03-31/videos/penguindemo.mp4'\n",
        "\n",
        "deeplabcut.convert_raw_tracks_to_h5(path_config_file, picklefile)\n",
        "deeplabcut.filterpredictions(path_config_file, \n",
        "                                 videofile_path, \n",
        "                                 videotype=VideoType, \n",
        "                                 track_method = tracktype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk4xGb8Ftf3B"
      },
      "source": [
        "## Create plots of your trajectories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX21zZbXoEKJ"
      },
      "source": [
        "deeplabcut.plot_trajectories(path_config_file,videofile_path, videotype=VideoType, track_method=tracktype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqaCw15v8EmB"
      },
      "source": [
        "Now you can look at the plot-poses file and check the \"plot-likelihood.png\" might want to change the \"p-cutoff\" in the config.yaml file so that you have only high confidnece points plotted in the video. i.e. ~0.8 or 0.9. The current default is 0.4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCrUvQIvoEKD"
      },
      "source": [
        "## Create labeled video:\n",
        "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDF7Q7KoEKE"
      },
      "source": [
        "deeplabcut.create_labeled_video(path_config_file,\n",
        "                                videofile_path, \n",
        "                                shuffle=shuffle, \n",
        "                                draw_skeleton=True, \n",
        "                                videotype=VideoType, \n",
        "                                save_frames=False,\n",
        "                                filtered=True, \n",
        "                                track_method = tracktype)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}